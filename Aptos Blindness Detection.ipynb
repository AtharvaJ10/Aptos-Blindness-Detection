{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test_images', 'train_images', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2588, 1958)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('../input/train_images/7b9d519cbd66.png')\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  001639a390f0          4\n",
       "2  0024cdab0c1e          1\n",
       "3  002c21358ce6          0\n",
       "4  005b95c28852          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3662 entries, 0 to 3661\n",
      "Data columns (total 2 columns):\n",
      "id_code      3662 non-null object\n",
      "diagnosis    3662 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.3+ KB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1928 entries, 0 to 1927\n",
      "Data columns (total 1 columns):\n",
      "id_code    1928 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 15.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "print()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbcd9256ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Dense,Dropout,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(96, 96, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32,3,3,input_shape=(96,96,3),activation='relu'))\n",
    "model.add(Convolution2D(32,3,3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(output_dim=128 , activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(output_dim=5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255 , \n",
    "                                   shear_range = 0.2 ,\n",
    "                                   zoom_range = 0.2 ,\n",
    "                                   horizontal_flip = True,\n",
    "                                  validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_code'] = train['id_code'].astype('str')+'.png'\n",
    "train['diagnosis'] = train['diagnosis'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2930 validated image filenames belonging to 5 classes.\n",
      "Found 732 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen=train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(96,96),\n",
    "    subset='training')\n",
    "\n",
    "test_gen=train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\", \n",
    "    target_size=(96,96),\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - 427s 5s/step - loss: 1.0562 - acc: 0.6098 - val_loss: 0.9377 - val_acc: 0.6680\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 381s 4s/step - loss: 0.8740 - acc: 0.6950 - val_loss: 0.8513 - val_acc: 0.7022\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 381s 4s/step - loss: 0.8227 - acc: 0.7167 - val_loss: 0.8253 - val_acc: 0.7022\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.8143 - acc: 0.7128 - val_loss: 0.8112 - val_acc: 0.7008\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 375s 4s/step - loss: 0.7974 - acc: 0.7233 - val_loss: 0.8361 - val_acc: 0.7090\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 372s 4s/step - loss: 0.7920 - acc: 0.7148 - val_loss: 0.8292 - val_acc: 0.7036\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 374s 4s/step - loss: 0.7849 - acc: 0.7239 - val_loss: 0.8115 - val_acc: 0.7090\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.7594 - acc: 0.7220 - val_loss: 0.8032 - val_acc: 0.7158\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.7652 - acc: 0.7230 - val_loss: 0.8100 - val_acc: 0.7145\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 372s 4s/step - loss: 0.7519 - acc: 0.7258 - val_loss: 0.7625 - val_acc: 0.7227\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.7257 - acc: 0.7360 - val_loss: 0.7903 - val_acc: 0.7186\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 375s 4s/step - loss: 0.7276 - acc: 0.7321 - val_loss: 0.7914 - val_acc: 0.7199\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 375s 4s/step - loss: 0.7098 - acc: 0.7404 - val_loss: 0.7468 - val_acc: 0.7227\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.7006 - acc: 0.7403 - val_loss: 0.7558 - val_acc: 0.7240\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.6895 - acc: 0.7494 - val_loss: 0.7721 - val_acc: 0.7145\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 379s 4s/step - loss: 0.6776 - acc: 0.7538 - val_loss: 0.7768 - val_acc: 0.7077\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 371s 4s/step - loss: 0.6838 - acc: 0.7503 - val_loss: 0.7595 - val_acc: 0.7172\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 372s 4s/step - loss: 0.6533 - acc: 0.7543 - val_loss: 0.8107 - val_acc: 0.7240\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.6472 - acc: 0.7608 - val_loss: 0.8558 - val_acc: 0.6954\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 374s 4s/step - loss: 0.6304 - acc: 0.7692 - val_loss: 0.7976 - val_acc: 0.7063\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 378s 4s/step - loss: 0.6230 - acc: 0.7663 - val_loss: 0.7612 - val_acc: 0.7240\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.5975 - acc: 0.7748 - val_loss: 0.7821 - val_acc: 0.7350\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 370s 4s/step - loss: 0.6102 - acc: 0.7751 - val_loss: 0.7917 - val_acc: 0.7158\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 370s 4s/step - loss: 0.5909 - acc: 0.7799 - val_loss: 0.7723 - val_acc: 0.7213\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 365s 4s/step - loss: 0.5705 - acc: 0.7874 - val_loss: 0.8120 - val_acc: 0.7186\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 366s 4s/step - loss: 0.5602 - acc: 0.7922 - val_loss: 0.7668 - val_acc: 0.7322\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 367s 4s/step - loss: 0.5335 - acc: 0.7943 - val_loss: 0.8528 - val_acc: 0.7172\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 366s 4s/step - loss: 0.5200 - acc: 0.8036 - val_loss: 0.8477 - val_acc: 0.7077\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 357s 4s/step - loss: 0.5287 - acc: 0.7926 - val_loss: 0.8206 - val_acc: 0.7131\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 353s 4s/step - loss: 0.4935 - acc: 0.8099 - val_loss: 0.8274 - val_acc: 0.7295\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 358s 4s/step - loss: 0.4873 - acc: 0.8228 - val_loss: 0.8355 - val_acc: 0.7172\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 357s 4s/step - loss: 0.4713 - acc: 0.8255 - val_loss: 0.8650 - val_acc: 0.7377\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 364s 4s/step - loss: 0.4861 - acc: 0.8147 - val_loss: 0.8644 - val_acc: 0.7077\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 362s 4s/step - loss: 0.4647 - acc: 0.8238 - val_loss: 0.9670 - val_acc: 0.7145\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 365s 4s/step - loss: 0.4733 - acc: 0.8268 - val_loss: 0.8627 - val_acc: 0.7186\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 372s 4s/step - loss: 0.4341 - acc: 0.8379 - val_loss: 0.9229 - val_acc: 0.7158\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 376s 4s/step - loss: 0.4233 - acc: 0.8400 - val_loss: 0.8886 - val_acc: 0.7199\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 375s 4s/step - loss: 0.4101 - acc: 0.8459 - val_loss: 0.9950 - val_acc: 0.7227\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.4017 - acc: 0.8464 - val_loss: 1.0131 - val_acc: 0.7022\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 376s 4s/step - loss: 0.3922 - acc: 0.8503 - val_loss: 1.0803 - val_acc: 0.7199\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.3916 - acc: 0.8494 - val_loss: 1.0071 - val_acc: 0.6995\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.3744 - acc: 0.8622 - val_loss: 1.0339 - val_acc: 0.7240\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 377s 4s/step - loss: 0.3527 - acc: 0.8726 - val_loss: 1.1004 - val_acc: 0.6940\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 379s 4s/step - loss: 0.3589 - acc: 0.8637 - val_loss: 1.0935 - val_acc: 0.6940\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 375s 4s/step - loss: 0.3472 - acc: 0.8697 - val_loss: 1.1265 - val_acc: 0.7199\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 382s 4s/step - loss: 0.3410 - acc: 0.8763 - val_loss: 1.1378 - val_acc: 0.6981\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 381s 4s/step - loss: 0.3245 - acc: 0.8772 - val_loss: 1.0252 - val_acc: 0.7227\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 378s 4s/step - loss: 0.3069 - acc: 0.8821 - val_loss: 1.1848 - val_acc: 0.6926\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 383s 4s/step - loss: 0.2997 - acc: 0.8915 - val_loss: 1.1655 - val_acc: 0.7213\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 378s 4s/step - loss: 0.2916 - acc: 0.8883 - val_loss: 1.1775 - val_acc: 0.7186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbcdbb7deb8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen,              \n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=test_gen,                    \n",
    "                    validation_steps=len(test_gen),\n",
    "                    epochs=50,\n",
    "                    use_multiprocessing = True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['id_code'] = test['id_code'].astype(str)+'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1928 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "submission=test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=\"../input/test_images\",\n",
    "    x_col=\"id_code\",    \n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    class_mode=None, \n",
    "    target_size=(96,96)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(submission,steps = len(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['diagnosis'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('aptos_blindness_detection.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
